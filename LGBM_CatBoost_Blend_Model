{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":116092,"databundleVersionId":13860829,"sourceType":"competition"},{"sourceId":13424641,"sourceType":"datasetVersion","datasetId":8520630}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ===============================================================\n# üß† CATBOOST + LIGHTGBM BLEND ‚Äî Feature-Enhanced Version\n# ===============================================================\n\nimport pandas as pd\nimport numpy as np\nfrom catboost import CatBoostClassifier, Pool\nfrom sklearn.metrics import roc_auc_score, log_loss\nfrom sklearn.isotonic import IsotonicRegression\nimport lightgbm as lgb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-19T10:02:16.330847Z","iopub.execute_input":"2025-10-19T10:02:16.331421Z","iopub.status.idle":"2025-10-19T10:02:23.360354Z","shell.execute_reply.started":"2025-10-19T10:02:16.331393Z","shell.execute_reply":"2025-10-19T10:02:23.359629Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# ---------------------------------------------------------------\n# üì¶ Load Engineered Base Features\n# ---------------------------------------------------------------\ntrain = pd.read_csv(\"/kaggle/input/feature-engineered-csvs/train_features(1).csv\")\ntest  = pd.read_csv(\"/kaggle/input/feature-engineered-csvs/test_features(1).csv\")\n\nprint(\"‚úÖ Data loaded\")\nprint(f\"Train shape: {train.shape} | Test shape: {test.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T10:02:58.402471Z","iopub.execute_input":"2025-10-19T10:02:58.403093Z","iopub.status.idle":"2025-10-19T10:03:01.862436Z","shell.execute_reply.started":"2025-10-19T10:02:58.403064Z","shell.execute_reply":"2025-10-19T10:03:01.861556Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Data loaded\nTrain shape: (133287, 87) | Test shape: (43006, 86)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ---------------------------------------------------------------\n# üßÆ Feature Engineering: Temporal Deltas & Ratios (3m vs 6m)\n# ---------------------------------------------------------------\ndef add_temporal_deltas(df):\n    base_features = set()\n    for col in df.columns:\n        if col.endswith(\"_3m\"):\n            base = col[:-3]  # remove '_3m'\n            if f\"{base}_6m\" in df.columns:\n                base_features.add(base)\n    print(f\"üîç Found {len(base_features)} base features with 3m & 6m\")\n\n    for base in base_features:\n        c3, c6 = f\"{base}_3m\", f\"{base}_6m\"\n        df[f\"{base}_delta_3m6m\"]  = df[c3] - df[c6]\n        df[f\"{base}_ratio_3m6m\"]  = df[c3] / df[c6].replace(0, np.nan)\n        df[f\"{base}_growth_3m6m\"] = (df[c3] - df[c6]) / df[c6].replace(0, np.nan)\n\n    return df.replace([np.inf, -np.inf], np.nan)\n\ntrain = add_temporal_deltas(train)\ntest  = add_temporal_deltas(test)\nprint(f\"‚úÖ Shapes after new features ‚Äî Train: {train.shape} | Test: {test.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T10:03:16.096064Z","iopub.execute_input":"2025-10-19T10:03:16.096459Z","iopub.status.idle":"2025-10-19T10:03:16.932594Z","shell.execute_reply.started":"2025-10-19T10:03:16.096430Z","shell.execute_reply":"2025-10-19T10:03:16.931729Z"}},"outputs":[{"name":"stdout","text":"üîç Found 23 base features with 3m & 6m\nüîç Found 23 base features with 3m & 6m\n‚úÖ Shapes after new features ‚Äî Train: (133287, 156) | Test: (43006, 155)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# ---------------------------------------------------------------\n# ‚è≥ Leak-free Time Split\n# ---------------------------------------------------------------\ntrain[\"ref_date\"] = pd.to_datetime(train[\"ref_date\"])\ncutoff = \"2018-11-01\"\n\ntrain_part = train[train[\"ref_date\"] < cutoff].copy()\nvalid_part = train[train[\"ref_date\"] >= cutoff].copy()\n\nX_train = train_part.drop(columns=[\"cust_id\", \"ref_date\", \"churn\"])\ny_train = train_part[\"churn\"].astype(int)\nX_valid = valid_part.drop(columns=[\"cust_id\", \"ref_date\", \"churn\"])\ny_valid = valid_part[\"churn\"].astype(int)\n\nprint(f\"üìÖ Train: {X_train.shape} | Valid: {X_valid.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T10:03:36.992896Z","iopub.execute_input":"2025-10-19T10:03:36.993190Z","iopub.status.idle":"2025-10-19T10:03:37.251663Z","shell.execute_reply.started":"2025-10-19T10:03:36.993168Z","shell.execute_reply":"2025-10-19T10:03:37.250800Z"}},"outputs":[{"name":"stdout","text":"üìÖ Train: (118422, 153) | Valid: (14865, 153)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# ---------------------------------------------------------------\n# üî¢ Categorical columns (shared across models)\n# ---------------------------------------------------------------\ncat_cols = [\"gender\", \"province\", \"religion\", \"work_type\", \"work_sector\", \"season\"]\ncat_cols = [c for c in cat_cols if c in X_train.columns]\nprint(f\"üß© Using {len(cat_cols)} categorical features: {cat_cols}\")\n\n# LightGBM prefers pandas categorical dtype for categorical features\nfor c in cat_cols:\n    X_train[c] = X_train[c].astype(\"category\")\n    X_valid[c] = X_valid[c].astype(\"category\")\n\n# Test set same treatment\nX_test = test.drop(columns=[\"cust_id\", \"ref_date\"]).copy()\nfor c in cat_cols:\n    if c in X_test.columns:\n        X_test[c] = X_test[c].astype(\"category\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T10:03:44.162388Z","iopub.execute_input":"2025-10-19T10:03:44.162700Z","iopub.status.idle":"2025-10-19T10:03:44.275467Z","shell.execute_reply.started":"2025-10-19T10:03:44.162675Z","shell.execute_reply":"2025-10-19T10:03:44.274562Z"}},"outputs":[{"name":"stdout","text":"üß© Using 6 categorical features: ['gender', 'province', 'religion', 'work_type', 'work_sector', 'season']\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# ---------------------------------------------------------------\n# ‚öñÔ∏è Class imbalance\n# ---------------------------------------------------------------\nneg, pos = np.bincount(y_train)\nscale_pos_weight = neg / max(1, pos)\nprint(f\"Pos/Neg = {pos}/{neg} ‚Üí class_weight ‚âà {scale_pos_weight:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T10:03:51.247640Z","iopub.execute_input":"2025-10-19T10:03:51.247939Z","iopub.status.idle":"2025-10-19T10:03:51.254089Z","shell.execute_reply.started":"2025-10-19T10:03:51.247916Z","shell.execute_reply":"2025-10-19T10:03:51.253053Z"}},"outputs":[{"name":"stdout","text":"Pos/Neg = 16906/101516 ‚Üí class_weight ‚âà 6.00\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# ===============================================================\n# üöÄ Model A: CatBoost\n# ===============================================================\ntrain_pool = Pool(X_train, y_train, cat_features=cat_cols)\nvalid_pool = Pool(X_valid, y_valid, cat_features=cat_cols)\n\ncb = CatBoostClassifier(\n    iterations=3000,\n    learning_rate=0.03,\n    depth=8,\n    l2_leaf_reg=3,\n    random_seed=42,\n    loss_function=\"Logloss\",\n    eval_metric=\"AUC\",\n    class_weights=[1.0, scale_pos_weight],\n    od_type=\"Iter\",\n    od_wait=200,\n    task_type=\"CPU\",\n    verbose=False\n)\n\nprint(\"\\nüöÄ Training CatBoost...\")\ncb.fit(train_pool, eval_set=valid_pool, use_best_model=True, verbose=False)\n\ncb_val = cb.predict_proba(X_valid)[:, 1]\ncb_auc = roc_auc_score(y_valid, cb_val)\ncb_ll  = log_loss(y_valid, cb_val)\nprint(f\"‚úÖ CatBoost    ‚Üí AUC: {cb_auc:.5f} | LogLoss: {cb_ll:.5f}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T10:04:21.099531Z","iopub.execute_input":"2025-10-19T10:04:21.100382Z","iopub.status.idle":"2025-10-19T10:06:10.789870Z","shell.execute_reply.started":"2025-10-19T10:04:21.100353Z","shell.execute_reply":"2025-10-19T10:06:10.788938Z"}},"outputs":[{"name":"stdout","text":"\nüöÄ Training CatBoost...\n‚úÖ CatBoost    ‚Üí AUC: 0.71080 | LogLoss: 0.59976\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# ===============================================================\n# üöÄ Model B: LightGBM (Sklearn API)\n# ===============================================================\n# Note: We use a conservative, robust config. You can tune further if needed.\nlgbm = lgb.LGBMClassifier(\n    n_estimators=5000,\n    learning_rate=0.02,\n    num_leaves=64,\n    max_depth=-1,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    reg_alpha=0.1,\n    reg_lambda=0.5,\n    objective=\"binary\",\n    metric=\"auc\",\n    random_state=42,\n    n_jobs=-1,\n    # handle imbalance\n    scale_pos_weight=scale_pos_weight\n)\n\nprint(\"\\nüöÄ Training LightGBM...\")\nlgbm.fit(\n    X_train, y_train,\n    eval_set=[(X_valid, y_valid)],\n    eval_metric=\"auc\",\n    callbacks=[lgb.early_stopping(stopping_rounds=300, verbose=False)]\n)\n\nlgb_val = lgbm.predict_proba(X_valid)[:, 1]\nlgb_auc = roc_auc_score(y_valid, lgb_val)\nlgb_ll  = log_loss(y_valid, lgb_val)\nprint(f\"‚úÖ LightGBM    ‚Üí AUC: {lgb_auc:.5f} | LogLoss: {lgb_ll:.5f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T10:06:23.435963Z","iopub.execute_input":"2025-10-19T10:06:23.436710Z","iopub.status.idle":"2025-10-19T10:06:47.425378Z","shell.execute_reply.started":"2025-10-19T10:06:23.436682Z","shell.execute_reply":"2025-10-19T10:06:47.424473Z"}},"outputs":[{"name":"stdout","text":"\nüöÄ Training LightGBM...\n[LightGBM] [Info] Number of positive: 16906, number of negative: 101516\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.123221 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26085\n[LightGBM] [Info] Number of data points in the train set: 118422, number of used features: 148\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142761 -> initscore=-1.792548\n[LightGBM] [Info] Start training from score -1.792548\n‚úÖ LightGBM    ‚Üí AUC: 0.70820 | LogLoss: 0.57476\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# ===============================================================\n# üîó Blend Optimization (validation)\n# ===============================================================\n# We find weight w (0..1) minimizing LogLoss of:  w*cb + (1-w)*lgb\nws = np.linspace(0.0, 1.0, 51)  # 0.00, 0.02, ..., 1.00\nbest_w, best_ll, best_auc = None, 1e9, -1\n\nfor w in ws:\n    blend = w * cb_val + (1 - w) * lgb_val\n    ll = log_loss(y_valid, blend)\n    auc = roc_auc_score(y_valid, blend)\n    if ll < best_ll:\n        best_ll, best_auc, best_w = ll, auc, w\n\nprint(f\"\\nüîé Optimal blend weight (CatBoost): w = {best_w:.2f}\")\nprint(f\"üîó Blended (uncalibrated) ‚Üí AUC: {best_auc:.5f} | LogLoss: {best_ll:.5f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T10:06:59.329699Z","iopub.execute_input":"2025-10-19T10:06:59.330031Z","iopub.status.idle":"2025-10-19T10:06:59.802130Z","shell.execute_reply.started":"2025-10-19T10:06:59.330001Z","shell.execute_reply":"2025-10-19T10:06:59.801349Z"}},"outputs":[{"name":"stdout","text":"\nüîé Optimal blend weight (CatBoost): w = 0.00\nüîó Blended (uncalibrated) ‚Üí AUC: 0.70820 | LogLoss: 0.57476\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# ===============================================================\n# üéØ Calibration on blended validation predictions\n# ===============================================================\nblend_val = best_w * cb_val + (1 - best_w) * lgb_val\n\niso = IsotonicRegression(out_of_bounds=\"clip\")\niso.fit(blend_val, y_valid)\n\nblend_val_cal = iso.predict(blend_val)\nauc_cal = roc_auc_score(y_valid, blend_val_cal)\nll_cal  = log_loss(y_valid, blend_val_cal)\n\nprint(f\"\\nüéØ Calibrated Blend ‚Üí AUC: {auc_cal:.5f} | LogLoss: {ll_cal:.5f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T10:07:05.990224Z","iopub.execute_input":"2025-10-19T10:07:05.990560Z","iopub.status.idle":"2025-10-19T10:07:06.012422Z","shell.execute_reply.started":"2025-10-19T10:07:05.990535Z","shell.execute_reply":"2025-10-19T10:07:06.011570Z"}},"outputs":[{"name":"stdout","text":"\nüéØ Calibrated Blend ‚Üí AUC: 0.71081 | LogLoss: 0.35563\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# ===============================================================\n# üíæ Test-time predictions & submissions\n# ===============================================================\ncb_test  = cb.predict_proba(X_test)[:, 1]\nlgb_test = lgbm.predict_proba(X_test)[:, 1]\n\nblend_test = best_w * cb_test + (1 - best_w) * lgb_test\nblend_test_cal = iso.predict(blend_test)\n\n# Uncalibrated blend\nsub_uncal = pd.DataFrame({\n    \"cust_id\": test[\"cust_id\"],\n    \"churn\": blend_test\n})\nsub_uncal.to_csv(\"submission_blend_uncalibrated.csv\", index=False)\n\n# Calibrated blend\nsub_cal = pd.DataFrame({\n    \"cust_id\": test[\"cust_id\"],\n    \"churn\": blend_test_cal\n})\nsub_cal.to_csv(\"submission_blend_calibrated.csv\", index=False)\n\nprint(\"\\nüíæ Saved:\")\nprint(\" - submission_blend_uncalibrated.csv\")\nprint(\" - submission_blend_calibrated.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T10:07:11.280505Z","iopub.execute_input":"2025-10-19T10:07:11.281190Z","iopub.status.idle":"2025-10-19T10:07:11.750024Z","shell.execute_reply.started":"2025-10-19T10:07:11.281161Z","shell.execute_reply":"2025-10-19T10:07:11.749045Z"}},"outputs":[{"name":"stdout","text":"\nüíæ Saved:\n - submission_blend_uncalibrated.csv\n - submission_blend_calibrated.csv\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# ===============================================================\n# üìä Final local summary\n# ===============================================================\nprint(\"\\nüìä Local Validation Summary\")\nprint(f\"CatBoost              ‚Üí AUC: {cb_auc:.5f} | LogLoss: {cb_ll:.5f}\")\nprint(f\"LightGBM              ‚Üí AUC: {lgb_auc:.5f} | LogLoss: {lgb_ll:.5f}\")\nprint(f\"Blend (uncalibrated)  ‚Üí AUC: {best_auc:.5f} | LogLoss: {best_ll:.5f}  (w={best_w:.2f})\")\nprint(f\"Blend (calibrated)    ‚Üí AUC: {auc_cal:.5f} | LogLoss: {ll_cal:.5f}   ‚úÖ use this for LB\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T10:07:15.046965Z","iopub.execute_input":"2025-10-19T10:07:15.047374Z","iopub.status.idle":"2025-10-19T10:07:15.053163Z","shell.execute_reply.started":"2025-10-19T10:07:15.047343Z","shell.execute_reply":"2025-10-19T10:07:15.052420Z"}},"outputs":[{"name":"stdout","text":"\nüìä Local Validation Summary\nCatBoost              ‚Üí AUC: 0.71080 | LogLoss: 0.59976\nLightGBM              ‚Üí AUC: 0.70820 | LogLoss: 0.57476\nBlend (uncalibrated)  ‚Üí AUC: 0.70820 | LogLoss: 0.57476  (w=0.00)\nBlend (calibrated)    ‚Üí AUC: 0.71081 | LogLoss: 0.35563   ‚úÖ use this for LB\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}